{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ab7c40-c0da-4b75-a7b6-3822523f7218",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "## Question `2` (Decision Trees)\n",
    "\n",
    "| | |\n",
    "|-|-|\n",
    "| Course | Statistical Methods in AI |\n",
    "| Release Date | `19.01.2023` |\n",
    "| Due Date | `29.01.2023` |\n",
    "\n",
    "This assignment will have you working and experimenting with decision trees. Initially, you will be required to implement a decision tree classifier by choosing thresholds based on various impurity measures and reporting the scores. Later, you can experiment with the `scikit-learn` implementation of decision trees, and how various other parameters can be leveraged for better performance.\n",
    "\n",
    "The dataset is a very simple one, the [banknote authentication dataset](https://archive.ics.uci.edu/ml/datasets/banknote+authentication). It has 5 columns, the first 4 are the features, and the last one is the class label. The features are the variance, skewness, curtosis and entropy of the [wavelet transformed](https://en.wikipedia.org/wiki/Wavelet_transform) image of the banknote. The class label is 1 if the banknote is authentic, and 0 if it is forged. The data is present in `bankAuth.txt`. There are a total of 1372 samples in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2422c78-b240-48ca-b6a0-cc8b88562670",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01616b64-1baa-4cda-9894-5ffac51ec662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# additional imports if necessary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5653b9d8-2250-4b8e-820f-71ba9ccd5cf9",
   "metadata": {},
   "source": [
    "### Impurity Measures\n",
    "\n",
    "Decision trees are only as good as the impurity measure used to choose the best split. In this section, you will be required to implement the following impurity measures and use them to build a decision tree classifier.\n",
    "\n",
    "1. Gini Index\n",
    "2. Entropy/Log loss\n",
    "3. Misclassification Error\n",
    "\n",
    "Write functions that calculate the impurity measures for a given set of labels. The functions should take in a list of labels and return the impurity measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a37b889-d182-441a-b7ae-0803e65aff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def giniIndex(items):\n",
    "    zeroCount = 0\n",
    "    oneCount = 0\n",
    "    for item in items:\n",
    "        if item[-1] == 0:\n",
    "            zeroCount += 1\n",
    "        else:\n",
    "            oneCount += 1\n",
    "\n",
    "    N = float(items.shape[0])\n",
    "    oneFreq = oneCount/N\n",
    "    zeroFreq = zeroCount/N\n",
    "\n",
    "    gini = oneFreq*(1.0 - oneFreq) * zeroFreq*(1.0 - zeroFreq)\n",
    "    return gini\n",
    "\n",
    "def entropy(items):\n",
    "    zeroCount = 0\n",
    "    oneCount = 0\n",
    "    for item in items:\n",
    "        if item[-1] == 0:\n",
    "            zeroCount += 1\n",
    "        else:\n",
    "            oneCount += 1\n",
    "\n",
    "    N = float(items.shape[0])\n",
    "    oneFreq = oneCount/N\n",
    "    zeroFreq = zeroCount/N\n",
    "\n",
    "    S = -(np.log(oneFreq) * oneFreq + np.log(zeroFreq)*zeroFreq) \n",
    "    return S\n",
    "\n",
    "def misclassificationError(items):\n",
    "    zeroCount = 0\n",
    "    oneCount = 0\n",
    "    for item in items:\n",
    "        if item[-1] == 0:\n",
    "            zeroCount += 1\n",
    "        else:\n",
    "            oneCount += 1\n",
    "\n",
    "    N = float(items.shape[0])\n",
    "    oneFreq = oneCount/N\n",
    "    zeroFreq = zeroCount/N\n",
    "\n",
    "    if oneFreq > zeroFreq:\n",
    "        msce = 1 - oneFreq\n",
    "    else:\n",
    "        msce = 1 - zeroFreq\n",
    "    return msce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bfcc68-388e-4da8-ad87-270ef1212cdc",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "Fit a decision tree using any one of the above impurity measures with a depth of 3. This means you will have eight leaf nodes and seven internal nodes. Report the threshold values at each internal node and the impurity measure at the final leaf node with the label. Also report the accuracy of the classifier on the training and test data (instructions for splitting the data will be given in the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3939308e-294f-4d0e-a1af-1589906d5129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "class Partition():\n",
    "    def __init__(self, featureNum: int, value: float, isLessThan: bool):\n",
    "        self.featureNum = featureNum\n",
    "        self.value = value\n",
    "        self.isLessThan = isLessThan\n",
    "\n",
    "        if featureNum >= 4:\n",
    "            print(\"Warning: Invalid feature num\")\n",
    "\n",
    "    # pass a np array of items\n",
    "    def __call__(self, items): \n",
    "        # False -> left node, True -> right node\n",
    "        result = np.array(items.shape[0])\n",
    "\n",
    "        result = \n",
    "\n",
    "        if item[self.featureNum] < self.value:\n",
    "            result = True\n",
    "        \n",
    "        if not self.isLessThan:\n",
    "            result = not result\n",
    "\n",
    "        return result\n",
    "\n",
    "class DecisionTree():\n",
    "    \"\"\"\n",
    "                1\n",
    "           2         3\n",
    "        4    5    6     7   \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, trainData, impurity=giniIndex):\n",
    "        self.partitions = [Partition(-1,0.0,False)] * 7\n",
    "        self.impurity = impurity\n",
    "        self.trainData = trainData\n",
    "\n",
    "        \n",
    "    def splitAtPartition(self, partitionNum: int, data):\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee93dc80-27a8-466e-91f6-cc16d2f87187",
   "metadata": {},
   "source": [
    "### `sklearn` Decision Tree Experiments\n",
    "\n",
    "1. Scikit-learn has two decision tree implementations: [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) and [`DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html). \n",
    "\n",
    "When would you use one over the other? What would you use in the case of the banknote authentication dataset? Explain the changes that need to be made in the dataset to use the other implementation.\n",
    "\n",
    "2. Fit a decision tree to the training set. Change various parameters and compare them to one another. Mainly try and experiment with the `criterion`, `max_depth` and `min_samples_split` parameters. Report the accuracy on the training and test set for each of the experiments while varying the parameters for comparison purposes.\n",
    "\n",
    "3. Plot your trees !! (optional) (for visualization)\n",
    "\n",
    "```python\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "def plotTree(tree):\n",
    "    \"\"\"\n",
    "    tree: Tree instance that is the result of fitting a DecisionTreeClassifier\n",
    "          or a DecisionTreeRegressor.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(30,20))\n",
    "    plot_tree(tree, filled=True, rounded=True,\n",
    "                  class_names=['forged', 'authentic'],\n",
    "                  feature_names=['var', 'skew', 'curt', 'ent'])\n",
    "    plt.show()\n",
    "    return None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4f8dc0-50a7-4634-87cf-d75ccf3b43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af48e314-8c64-4fc2-b654-726d3549e42f",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "The data has been loaded onto a Pandas DataFrame. Try to get an initial feel for the data by using functions like `describe()`, `info()`, or maybe try to plot the data to check for any patterns.\n",
    "\n",
    "Note: To obtain the data from the UCI website, `wget` can be used followed by shuffling the samples using `shuf` and adding a header for easier reading via `pandas`. It is not necessary to view the data in a DataFrame and can be directly loaded onto NumPy as convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea8dd35b-09f6-4400-821b-d9aa0b07cd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1371 entries, 0 to 1370\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   3.6216    1371 non-null   float64\n",
      " 1   8.6661    1371 non-null   float64\n",
      " 2   -2.8073   1371 non-null   float64\n",
      " 3   -0.44699  1371 non-null   float64\n",
      " 4   0         1371 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 53.7 KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('bankAuth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e083bc34-cf20-41f5-a1ff-889beb22e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1cec0c-7433-4d38-875d-c9b25f2366b5",
   "metadata": {},
   "source": [
    "### Splitting the Data\n",
    "\n",
    "It is a good practice to split the data into training and test sets. This is to ensure that the model is not overfitting to the training data. The test set is used to evaluate the performance of the model on unseen data. The test set is not used to train the model in any way. The test set is only used to evaluate the performance of the model. You may use the `train_test_split` function from `sklearn.model_selection` to split the data into training and test sets.\n",
    "\n",
    "It is a good idea to move your data to NumPy arrays now as it will make computing easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc54272-3855-4601-8ad7-f3c3062a687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63938d1f-174f-4054-ba7f-82d73171f2e4",
   "metadata": {},
   "source": [
    "### Denouement\n",
    "\n",
    "Use this place to report all comparisons and wrap up the calls to the functions written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9acc1dad-a657-403b-9154-003961d241ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a4887ba97cd0453d407f2999ca251911114f05a0a638f9c2041832012853734"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
